{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#Regressão univariada"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#importa a biblioteca que cria a seção do spark\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["23/01/09 23:59:15 WARN Utils: Your hostname, Deboras-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.68.104 instead (on interface en0)\n","23/01/09 23:59:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"]},{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["23/01/09 23:59:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["#inicia a seção para a utilização do spark\n","spark = SparkSession\\\n","    .builder\\\n","    .appName(\"RegressaoLinear\")\\\n","    .getOrCreate() #cria a seção caso não exista ou obtém a já criada"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#define o diretório que contém o arquivo a ser utilizado\n","diretorioRegressao=\"./data/regressaoLinear.csv\" "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#importa os tipos\n","from pyspark.sql.types import * \n","\n","#define o esquema dos dados a serem lidos\n","#Define o tipo como struct, chama a variável independete de X e define como inteiro e chama a variável dependente de Y e define como string\n","#Para não dar erro depois, tem que chamar de X e Y\n","schema=StructType().add(\"X\",IntegerType(),True).add(\"Y\",StringType(),True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#carrega o arquivo no Spark com o esquema definido\n","pagamentoSeguro = spark.read.format('csv').schema(schema).options(header='true',delimiter=';').load(diretorioRegressao)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- X: integer (nullable = true)\n"," |-- Y: string (nullable = true)\n","\n"]}],"source":["#checa se esquema foi corretamente carregado\n","pagamentoSeguro.printSchema()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+\n","|  X|    Y|\n","+---+-----+\n","|108|392,5|\n","| 19| 46,2|\n","| 13| 15,7|\n","|124|422,2|\n","| 40|119,4|\n","+---+-----+\n","only showing top 5 rows\n","\n"]}],"source":["#mostra os primeiros 5 dados\n","pagamentoSeguro.show(5)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#importa funções\n","import pyspark.sql.functions as F\n","\n","#Altera o nome das variáveis para \"Apolices\" e \"Valor_Pago\"\n","pagamentoSeguro=pagamentoSeguro.select(F.col('X').alias(\"Apolices\"), F.col('Y').alias(\"Valor_Pago\"))  #adiciona nomes ao cabaçalho"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------+\n","|Apolices|Valor_Pago|\n","+--------+----------+\n","|     108|     392,5|\n","|      19|      46,2|\n","|      13|      15,7|\n","|     124|     422,2|\n","|      40|     119,4|\n","+--------+----------+\n","only showing top 5 rows\n","\n"]}],"source":["#checa alteração\n","pagamentoSeguro.show(5)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#Como os algoritmos separam inteiro de decimal com \".\", cria uma nova coluna com \".\" no lugar da \",\"\n","#Para que isso funcione, foi necessário definir o esquema com a variável Y como string!\n","pagamentoSeguroPonto=pagamentoSeguro.withColumn(\"Valor_Pago_Novo\", F.regexp_replace(F.col(\"Valor_Pago\"), \"[,]\", \".\")) "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------+---------------+\n","|Apolices|Valor_Pago|Valor_Pago_Novo|\n","+--------+----------+---------------+\n","|     108|     392,5|          392.5|\n","|      19|      46,2|           46.2|\n","|      13|      15,7|           15.7|\n","|     124|     422,2|          422.2|\n","|      40|     119,4|          119.4|\n","+--------+----------+---------------+\n","only showing top 5 rows\n","\n"]}],"source":["#checa alteração\n","pagamentoSeguroPonto.show(5)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["#Feita a substituição, transforma o tipo string para numérico\n","pagamentoSeguroFinal=pagamentoSeguroPonto.select(F.col('Apolices'),F.col('Valor_Pago_Novo'), pagamentoSeguroPonto.Valor_Pago_Novo.cast('float').alias('Valor_Pago_Float'))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+---------------+----------------+\n","|Apolices|Valor_Pago_Novo|Valor_Pago_Float|\n","+--------+---------------+----------------+\n","|     108|          392.5|           392.5|\n","|      19|           46.2|            46.2|\n","|      13|           15.7|            15.7|\n","|     124|          422.2|           422.2|\n","|      40|          119.4|           119.4|\n","+--------+---------------+----------------+\n","only showing top 5 rows\n","\n"]}],"source":["#checa alteração\n","pagamentoSeguroFinal.show(5)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Apolices: integer (nullable = true)\n"," |-- Valor_Pago_Novo: string (nullable = true)\n"," |-- Valor_Pago_Float: float (nullable = true)\n","\n"]}],"source":["#verifica esquema\n","pagamentoSeguroFinal.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["Iniciando o Processo de Regressão"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+-----------------+-----------------+\n","|summary|          Apolices|  Valor_Pago_Novo| Valor_Pago_Float|\n","+-------+------------------+-----------------+-----------------+\n","|  count|                63|               63|               63|\n","|   mean|22.904761904761905|98.18730158730159|98.18730196877131|\n","| stddev| 23.35194561605733|87.32755263404981|87.32755386147541|\n","|    min|                 0|                0|              0.0|\n","|    max|               124|             98.1|            422.2|\n","+-------+------------------+-----------------+-----------------+\n","\n"]}],"source":["#mostra informações básicas sobre os dados: count, mean, stddev, min e max\n","pagamentoSeguroFinal.describe().show()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Apolices: integer (nullable = true)\n"," |-- Valor_Pago_Novo: string (nullable = true)\n"," |-- Valor_Pago_Float: float (nullable = true)\n"," |-- features: vector (nullable = true)\n","\n"]}],"source":["#importa a biblioteca responsável por criar o vetor a partir da coluna\n","from pyspark.ml.feature import VectorAssembler\n","\n","#transformando os dados (linhas) em vetores que poderão ser lidos pelo algoritmo\n","#define o objeto para transformação\n","assembler = VectorAssembler(inputCols=['Apolices'], outputCol='features')  \n","\n","#aplica a transformação\n","df_seguro = assembler.transform(pagamentoSeguroFinal)\n","\n","# #verifica esquema\n","df_seguro.printSchema()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------------+\n","|features|Valor_Pago_Float|\n","+--------+----------------+\n","| [108.0]|           392.5|\n","|  [19.0]|            46.2|\n","|  [13.0]|            15.7|\n","| [124.0]|           422.2|\n","|  [40.0]|           119.4|\n","+--------+----------------+\n","only showing top 5 rows\n","\n"]}],"source":["#seleciona apenas colunas de interesse\n","df_seguro = df_seguro.select(['features','Valor_Pago_Float'])\n","\n","#checa alterações\n","df_seguro.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["Criando o Modelo de Regressão"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["23/01/10 00:03:41 WARN Instrumentation: [14a9ab7c] regParam is zero, which might cause numerical instability and overfitting.\n","23/01/10 00:03:41 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n","23/01/10 00:03:41 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n","23/01/10 00:03:41 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n","23/01/10 00:03:41 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"]}],"source":["# importa biblioteca que contém o modelo de regressão\n","from pyspark.ml.regression import LinearRegression\n","\n","#define o objeto a ser utilizado para regressão com máxima interação = 10 e a coluna Valor_Pago_Float como target (variável dependente)\n","lr = LinearRegression(maxIter=10, labelCol='Valor_Pago_Float') \n","\n","#cria o modelo de regressão linear com os parâmetros ajustados\n","lrModel = lr.fit(df_seguro)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Intercepto: 19.994485035718697\n","Coeficiente Angular: [3.41382361]\n"]}],"source":["#Mostra coeficientes angulares e lineares (a e b) da reta de regressão\n","print(f'Intercepto: {lrModel.intercept}\\nCoeficiente Angular: {lrModel.coefficients.values}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#print das estatísticas do modelo\n","modelsummary = lrModel.summary\n","\n","print(\"Variância Explicada:\", modelsummary.explainedVariance)\n","print('R_2: ', modelsummary.r2)\n","print('Erro médio quadrático: ',modelsummary.meanSquaredError)\n","\n","modelsummary.residuals.show(5)\n"]},{"cell_type":"markdown","metadata":{},"source":["Realizando a Previsão Através do Modelo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["modelsummary.predictions.show(5)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"},"name":"regressao","notebookId":3364351409033085,"vscode":{"interpreter":{"hash":"98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"}}},"nbformat":4,"nbformat_minor":0}
