{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programa Para o Twitter***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria a seção a ser utiliza para estabelecer a conexão \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkTwitterV02\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas utilizadas para realizar a análise dos textos\n",
    "from textblob import TextBlob  #utilizada para realizar o processamento do texto e análise de sentimento\n",
    "from googletrans import Translator #utilizado para traduzir textos \n",
    "from unidecode import unidecode  #utilizada para \"decodificar caracteres\" não textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 01:18:54 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "#cria o dataframe que será responsável por ler cada uma das linhas recebidas através do localhost e porta 9999\n",
    "# define a fonte (source) de dados\n",
    "twitters = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9995) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para realizar a tradução para o inglês \n",
    "def translate_udf(col):\n",
    "    trans_obj=Translator().translate(col)\n",
    "    return trans_obj.text\n",
    "\n",
    "#função para realizar a análise de sentimento\n",
    "def sentiment_udf(col):\n",
    "    sentiment_text=TextBlob(col)\n",
    "    return sentiment_text.polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição das função como User-Defined-Function\n",
    "unicode_udf_string = udf(lambda z: unidecode(z), StringType()) #define a função de decode para ser utilizada no dataframe\n",
    "group_by_sentiment = udf(lambda x: 'negativo' if x < -0.1 else 'positivo' if x > 0.1 else 'neutro',StringType())\n",
    "translate_udf_string = udf(translate_udf, StringType()) #define a função de tradução\n",
    "sentiment_udf_float = udf(sentiment_udf, FloatType()) #define a função de tradução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu  o meu cachorro, ele e o meu melhor amigo\n",
      "Me my dog, he is my best friend\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#testando funções\n",
    "teste=\"Eu ♥ o meu cachorro, ele é o meu melhor amigo\"\n",
    "decode=unidecode(teste)\n",
    "print(decode)\n",
    "decodeEN=Translator().translate(decode)\n",
    "print(decodeEN.text)\n",
    "a=str(decodeEN)\n",
    "sentiment = TextBlob(a)\n",
    "print(sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplica as funções udf para a seleção de colunas\n",
    "twitters_unicode=twitters.select( \"value\",unicode_udf_string(twitters.value).alias(\"unicoded\")) #decodifica\n",
    "twitters_uni_trans=twitters_unicode.select( \"value\",\"unicoded\",translate_udf_string(col(\"unicoded\")).alias(\"twitter_EN\")) #traduz\n",
    "twitters_uni_trans_sent=twitters_uni_trans.select(\"value\", \"unicoded\", \"twitter_EN\", sentiment_udf_float(col(\"twitter_EN\")).alias(\"analise\"))#análise de sentimento\n",
    "t_sent_label= twitters_uni_trans_sent.select(\"value\",\"unicoded\",\"twitter_EN\", \"analise\",group_by_sentiment(col(\"analise\")).alias(\"classificacao\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string, unicoded: string, twitter_EN: string, analise: float]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitters_uni_trans_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 01:29:53 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/hn/zqmlf1cd4s3_llkx270x0kw80000gn/T/temporary-99433e0b-032e-4909-8cfc-3bf2734722e7. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/01/28 01:29:53 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "query = twitters_uni_trans_sent \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "# query.awaitTermination() #aguarda até que a \"streaming query\" termine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# t_sent_count = t_sent_label.groupBy(\"classificacao\").count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define a consulta (query) e como deve ser realizada a saída (sink) para o stream criado \n",
    "#Dando ERRO!! =(\n",
    "# query = t_sent_count \\\n",
    "#     .writeStream \\\n",
    "#     .outputMode(\"update\") \\\n",
    "#     .format(\"console\") \\\n",
    "#     .start()\n",
    "\n",
    "# query.awaitTermination() #aguarda até que a \"streaming query\" termine "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
